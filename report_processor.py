# -*- coding: utf-8 -*-
import pandas as pd
import sys
import os
import re

def normalize_text(text):
    if pd.isna(text):
        return text
    text = str(text).strip()
    text = re.sub('[Ø£Ø¥Ø¢]', 'Ø§', text)
    return text

def process_and_highlight_duplicates(file_path):
    try:
        if not os.path.exists(file_path):
            print(f"Error: File not found at {file_path}", file=sys.stderr)
            return

        print("Starting data cleaning and duplicate highlighting...")
        df = pd.read_excel(file_path)
        
        # ğŸ”¥ ØªØ¹Ø¯ÙŠÙ„ Ø­Ø§Ø³Ù…: ØªØ­Ø¯ÙŠØ« Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
        # ØªÙ… Ø§Ø³ØªØ¨Ø¯Ø§Ù„ 'ØªØ§Ø±ÙŠØ® Ø§Ù„Ù†Ø´Ø§Ø·' Ø¨Ø§Ù„Ø¹Ù…ÙˆØ¯ÙŠÙ† Ø§Ù„Ø¬Ø¯ÙŠØ¯ÙŠÙ†
        # ÙˆØªÙ… ØªØ­Ø¯ÙŠØ« Ø¨Ù‚ÙŠØ© Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ù„ØªØ·Ø§Ø¨Ù‚ Ø§Ù„ÙÙˆØ±Ù… Ø§Ù„Ø¬Ø¯ÙŠØ¯
        key_columns = [
            'ØªØ§Ø±ÙŠØ® Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ù†Ø´Ø§Ø·', 
            'ØªØ§Ø±ÙŠØ® Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ù†Ø´Ø§Ø·',
            'Ø§Ø³Ù… Ø§Ù„Ù‚Ø·Ø§Ø¹', 
            'Ø§Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠØ©', 
            'Ø§Ù„Ø¥Ø¯Ø§Ø±Ø©',
            'Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ù†Ø´Ø§Ø·', 
            'Ø§Ø³Ù… Ø§Ù„Ù…Ù‚Ø¯Ù…', 
            'Ø§Ù„ÙØ¦Ø© Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØ© (ØªÙØ§ØµÙŠÙ„)'
        ]
        
        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù‚Ø¨Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§
        existing_key_columns = [col for col in key_columns if col in df.columns]
        if not existing_key_columns:
            print("Warning: No key columns found for duplicate check. Skipping.")
            return

        # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø¹Ù„Ù‰ Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†ØµÙˆØµ
        text_cols_to_clean = ['Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ù†Ø´Ø§Ø·', 'Ø§Ø³Ù… Ø§Ù„Ù…Ù‚Ø¯Ù…', 'Ø§Ù„ÙØ¦Ø© Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØ© (ØªÙØ§ØµÙŠÙ„)']
        for col in text_cols_to_clean:
            if col in df.columns:
                df[col] = df[col].apply(normalize_text)

        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©
        df['is_duplicate'] = df.duplicated(subset=existing_key_columns, keep='first')
        
        if not df['is_duplicate'].any():
            print("No duplicates found.")
            # Ù„Ø§ Ø¯Ø§Ø¹ÙŠ Ù„Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ø­ÙØ¸ Ø¥Ø°Ø§ Ù„Ù… ÙŠØªØºÙŠØ± Ø´ÙŠØ¡
            return

        print(f"Found {df['is_duplicate'].sum()} duplicate rows. Highlighting in red...")

        writer = pd.ExcelWriter(file_path, engine='xlsxwriter')
        df.drop(columns=['is_duplicate']).to_excel(writer, sheet_name='Ø§Ù„Ø±Ø¯ÙˆØ¯', index=False)
        
        workbook = writer.book
        worksheet = writer.sheets['Ø§Ù„Ø±Ø¯ÙˆØ¯']
        worksheet.right_to_left()

        red_format = workbook.add_format({'bg_color': '#FFC7CE'})
        
        for row_index in df.index:
            if df.loc[row_index, 'is_duplicate']:
                excel_row = row_index + 1
                worksheet.set_row(excel_row, None, red_format)
                
        writer.close()
        
        print("Data cleaning and highlighting complete.")

    except Exception as e:
        print(f"Error during Excel processing: {e}", file=sys.stderr)
        sys.exit(1)

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Error: Excel file path not provided.", file=sys.stderr)
        sys.exit(1)
        
    excel_path = sys.argv[1]
    process_and_highlight_duplicates(excel_path)